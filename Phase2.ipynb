{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!git clone https://github.com/XL2248/MSCTD.git"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MSCTD'...\n",
            "remote: Enumerating objects: 1217, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 1217 (delta 13), reused 7 (delta 3), pack-reused 1190\u001b[K\n",
            "Receiving objects: 100% (1217/1217), 102.24 MiB | 18.60 MiB/s, done.\n",
            "Resolving deltas: 100% (616/616), done.\n",
            "Updating files: 100% (934/934), done.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jMkyCAVvfF-",
        "outputId": "34090dcd-0ec8-479f-ed89-dde40b0566b7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYVQpT-vlTT",
        "outputId": "4de07449-3e40-479f-ca18-cee74ab8f9a3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Read main data from drive\n",
        "\n",
        "!unzip -q \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/deepproject/train_ende.zip\"\n",
        "!unzip -q \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/deepproject/test.zip\"\n",
        "!unzip -q \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/deepproject/dev.zip\"\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "vaOB6-b3vpRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor, Lambda, transforms\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import cv2\n",
        "import dlib\n",
        "import time\n",
        "from __future__ import print_function, division\n",
        "import copy\n",
        "import pathlib\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxg8LnMB3ctM",
        "outputId": "8cb13f1c-9840-49b1-dba1-b3dd9c59512f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "aW21-HWyv2xr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# english_dev : 5063\n",
        "# english_test : 5067\n",
        "# english_train : 20240\n",
        "# #--------------------\n",
        "# german_dev : 5063\n",
        "# german_test : 5067\n",
        "# german_train : 20240\n",
        "# #-------------------"
      ],
      "outputs": [],
      "metadata": {
        "id": "E5AOoCCqv7XP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "y_h = lambda y : torch.zeros(3, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)\n",
        "class MSCTDDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, path_to_dataset = None, transform=None, target_transform=None):\n",
        "        if path_to_dataset == 'path_to_dataset_train':\n",
        "            Data = 'train'\n",
        "            path_english_text = 'english_train'\n",
        "            path_sentiment_text = 'sentiment_train'\n",
        "            path_image = 'train_ende'\n",
        "        elif path_to_dataset == 'path_to_dataset_test':\n",
        "            Data = 'test'\n",
        "            path_download = 'test_ende'\n",
        "            path_english_text = 'english_test'\n",
        "            path_sentiment_text = 'sentiment_test'\n",
        "            path_image = 'test'\n",
        "        elif path_to_dataset == 'path_to_dataset_dev':\n",
        "            Data = 'dev'\n",
        "            path_download = 'dev'\n",
        "            path_english_text = 'english_dev'\n",
        "            path_sentiment_text = 'sentiment_dev'\n",
        "            path_image = 'dev'\n",
        "        else:\n",
        "            return TypeError, path_to_dataset + \" is invalid\"\n",
        "        #!unzip \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/deepproject/train_ende.zip\"\n",
        "        english_text_path = f\"/content/MSCTD/MSCTD_data/ende/{path_english_text}.txt\"\n",
        "        sentiment_path = f\"/content/MSCTD/MSCTD_data/ende/{path_sentiment_text}.txt\"\n",
        "        self.image_path = f\"/content/{path_image}/\"\n",
        "\n",
        "        with open(english_text_path) as f:\n",
        "          english_text = [line.strip() for line in f.readlines()]\n",
        "        print(f\"{Data} english_text\", len(english_text))\n",
        "        self.englishtext = english_text\n",
        "\n",
        "        with open(sentiment_path) as f:\n",
        "          sentiment = [line.strip() for line in f.readlines()]\n",
        "        self.sentiment = sentiment\n",
        "        print(f\"{Data} sentiment\", len(sentiment))\n",
        "        \n",
        "        Images = os.listdir(self.image_path)\n",
        "        Images.sort(key = lambda x:  int(x.split(\".\")[0]))\n",
        "        self.Images = Images\n",
        "        # self.target = target\n",
        "        # self.features = features\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentiment)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # img_path = os.path.join(self.image_path, self.Images[idx])\n",
        "\n",
        "        # img = cv.imread(img_path)\n",
        "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # Chnage channel due to imread function read images in BGR coding.\n",
        "        sntmnt = self.sentiment[idx]\n",
        "        englsh_txt = self.englishtext[idx]\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = y_h(sntmnt)\n",
        "        if self.transform:\n",
        "            # img = cv2.resize(img,(64,64))\n",
        "            # img = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])(img)\n",
        "            sntmnt = int(sntmnt)\n",
        "        return englsh_txt, sntmnt "
      ],
      "outputs": [],
      "metadata": {
        "id": "lEMHZIpVv8s8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "train = MSCTDDataset('path_to_dataset_train', target_transform = False)\n",
        "test = MSCTDDataset('path_to_dataset_test', target_transform = False)\n",
        "dev = MSCTDDataset('path_to_dataset_dev', target_transform = False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train english_text 20240\n",
            "train sentiment 20240\n",
            "test english_text 5067\n",
            "test sentiment 5067\n",
            "dev english_text 5063\n",
            "dev sentiment 5063\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdvqc_9Bv_F4",
        "outputId": "552f239b-ebcb-4ff7-824e-5f23436d5b9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "eng_list=[x[0] for x in train]\n",
        "\n",
        "# tfidf = TfidfVectorizer(ngram_range=(1,5), max_features=500000)\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_transformed = vectorizer.fit_transform(eng_list)\n",
        "vectorizer.get_feature_names_out()\n",
        "print(\"sample document:\")\n",
        "print(eng_list[0])\n",
        "print(\"\\nsample of tfidf vector:\")\n",
        "print(train_transformed[0])\n",
        "print(\"\\nsome of words that has been used as the features:\")\n",
        "print(vectorizer.get_feature_names_out()[1200:1220])\n",
        "\n",
        "# train_transformed should be used to train the model.\n",
        "# a good example can be found here:\n",
        "# https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdr5BDb_n6Lx",
        "outputId": "6b8de543-f3f4-4c72-998c-b7d6c49a5657"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample document:\n",
            "Okay. I'm confused.\n",
            "\n",
            "sample of tfidf vector:\n",
            "  (0, 1903)\t0.8884650114525932\n",
            "  (0, 5859)\t0.45894435765628894\n",
            "\n",
            "some of words that has been used as the features:\n",
            "['brilliant' 'brine' 'bring' 'bringing' 'brings' 'briny' 'briskly'\n",
            " 'bristol' 'britain' 'british' 'bro' 'broadcast' 'broadcasters'\n",
            " 'broadcasts' 'broadway' 'brochures' 'broke' 'broken' 'broker'\n",
            " 'bronchitis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kp5_AqVHrjtO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}